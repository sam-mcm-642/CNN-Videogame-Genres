{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfce_test = Sequential()\n",
    "Xception = keras.applications.Xception(include_top=False, weights=\"imagenet\")\n",
    "for layer in Xception.layers:\n",
    "    layer.trainable=False\n",
    "# for layer in Xception.layers[-4:]:\n",
    "#     layer.trainable=True\n",
    "bfce_test.add(Xception)\n",
    "bfce_test.add(Flatten())\n",
    "bfce_test.add(Dense(512, activation = \"relu\"))\n",
    "bfce_test.add(BatchNormalization())\n",
    "bfce_test.add(Dropout(.3))\n",
    "\n",
    "bfce_test.add(Dense(512, activation = \"relu\"))\n",
    "bfce_test.add(BatchNormalization())\n",
    "bfce_test.add(Dropout(.2))\n",
    "    \n",
    "bfce_test.add(Dense(512, activation = \"relu\"))\n",
    "bfce_test.add(BatchNormalization())\n",
    "bfce_test.add(Dropout(.2))\n",
    "\n",
    "bfce_test.add(Dense(512, activation = \"relu\"))\n",
    "bfce_test.add(BatchNormalization())\n",
    "bfce_test.add(Dropout(.2))\n",
    "\n",
    "\n",
    "\n",
    "bfce_test.add(Dense(37, activation='softmax'))\n",
    "\n",
    "bfce_test.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss = CategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.F1Score(average='weighted'), \"precision\", \"recall\"]\n",
    ")\n",
    "\n",
    "\n",
    "bfce_test.fit(train_generator, \n",
    "             epochs=1,\n",
    "             class_weight = class_weights\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Sequential()\n",
    "Xception = keras.applications.Xception(include_top=False, weights=\"imagenet\")\n",
    "for layer in Xception.layers:\n",
    "    layer.trainable=False\n",
    "# for layer in Xception.layers[-4:]:\n",
    "#     layer.trainable=True\n",
    "test.add(Xception)\n",
    "test.add(Flatten())\n",
    "test.add(Dense(512, activation = \"relu\"))\n",
    "test.add(BatchNormalization())\n",
    "test.add(Dropout(.5))\n",
    "\n",
    "test.add(Dense(512, activation = \"relu\"))\n",
    "test.add(BatchNormalization())\n",
    "test.add(Dropout(.2))\n",
    "    \n",
    "test.add(Dense(512, activation = \"relu\"))\n",
    "test.add(BatchNormalization())\n",
    "test.add(Dropout(.2))\n",
    "\n",
    "test.add(Dense(512, activation = \"relu\"))\n",
    "test.add(BatchNormalization())\n",
    "test.add(Dropout(.2))\n",
    "\n",
    "\n",
    "\n",
    "test.add(Dense(37, activation='sigmoid'))\n",
    "\n",
    "\n",
    "test.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss = BinaryCrossentropy(),\n",
    "    metrics = [keras.metrics.F1Score(average='weighted'), \"accuracy\", \"precision\", \"recall\"]\n",
    ")\n",
    "\n",
    "\n",
    "test.fit(train_generator, \n",
    "             steps_per_epoch=93307//batch_size, \n",
    "             epochs=1,\n",
    "             class_weight = class_weights\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "##Can't use adagrad for some reason, it won't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###AGGREGATE PREDICTIONS ACROSS ALL SCREENSHOTS OF A VIDEOGAME \n",
    "\n",
    "class AggregatePredictions(Callback):\n",
    "    def __init__(self, game_names):\n",
    "        super().__init__()\n",
    "        self.game_names = game_names\n",
    "        self.aggregated_predictions = defaultdict(list)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Iterate over each video-game\n",
    "        for game in self.game_names:\n",
    "            # Initialize an empty list to store predictions for this game\n",
    "            game_predictions = []\n",
    "            # Aggregate predictions across batches\n",
    "            for batch_predictions in self.aggregated_predictions[game]:\n",
    "                game_predictions.extend(batch_predictions)\n",
    "            # Take the mean prediction across all screenshots for each tag\n",
    "            avg_predictions = np.mean(game_predictions, axis=0)\n",
    "            # Store the aggregated predictions for this video-game\n",
    "            self.aggregated_predictions[game] = [avg_predictions]\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Retrieve predictions for each video-game from the current batch\n",
    "        batch_game_names = logs.get('appid', [])\n",
    "        batch_predictions = logs.get('predictions', [])\n",
    "        # Update aggregated predictions for each video-game\n",
    "        for game, predictions in zip(batch_game_names, batch_predictions):\n",
    "            self.aggregated_predictions[game].append(predictions)\n",
    "\n",
    "# Example usage:\n",
    "# Define your model and compile it\n",
    "# model = ...\n",
    "# model.compile(...)\n",
    "\n",
    "# Instantiate the AggregatePredictions callback\n",
    "# aggregate_predictions_callback = AggregatePredictions(game_names=['game1', 'game2'])\n",
    "\n",
    "# Train your model using the callback\n",
    "# model.fit(..., callbacks=[aggregate_predictions_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# You can pass a list of callbacks (as the keyword argument callbacks) to the following model methods:\n",
    "\n",
    "# keras.Model.fit()\n",
    "# keras.Model.evaluate()\n",
    "# keras.Model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define a custom metric class for F1 score\n",
    "class CustomF1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='custom_f1_score', **kwargs):\n",
    "        super(CustomF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.f1_score = self.add_weight(name='f1_score', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred_prob, **kwargs):\n",
    "        # Calculate the number of true labels per instance\n",
    "        num_true_labels = tf.reduce_sum(tf.cast(y_true > 0, tf.float32), axis=1, keepdims=True)\n",
    "        \n",
    "        # Calculate the threshold dynamically\n",
    "        threshold = 0.2 / num_true_labels\n",
    "\n",
    "        # Apply the threshold to obtain binary predictions\n",
    "        y_pred = tf.cast(y_pred_prob > threshold, tf.float32)\n",
    "        \n",
    "        # Calculate the F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        # Update the state of the F1 score metric\n",
    "        self.f1_score.assign(f1)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_score\n",
    "\n",
    "# Create an instance of the custom F1 score metric\n",
    "custom_f1_metric = CustomF1Score()\n",
    "\n",
    "# Update the state of the custom metric using the validation data\n",
    "custom_f1_metric.update_state(y_true, y_pred_prob)\n",
    "\n",
    "# Print the F1 score\n",
    "print(\"Custom F1 Score:\", custom_f1_metric.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###REPORT FOR CCE\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Get the predicted probabilities for the validation/test set\n",
    "#valid_generator.reset()\n",
    "#y_pred_prob = bfce_test.predict(valid_generator)\n",
    "\n",
    "# Get the ground truth labels for the validation/test set\n",
    "y_true = valid_generator.labels\n",
    "\n",
    "num_true_labels = np.sum(y_true > 0, axis=1) \n",
    "num_true_labels = num_true_labels[:, np.newaxis]\n",
    "\n",
    "y_true = valid_generator.labels*num_true_labels\n",
    "\n",
    "# Threshold the predicted probabilities to obtain binary predictions\n",
    "y_pred = (y_pred_prob > 0.2/num_true_labels).astype(int)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=tags_to_use)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOADING IMAGES IN BATCHES\n",
    "###This whole step os sp that the images are only loaded into memory and used for training in batches\n",
    "# Define custom image data generator so we can random crop and resize img in preprocessing\n",
    "##\n",
    "# class CustomImageDataGenerator(ImageDataGenerator):\n",
    "#     def __init__(self, *args, crop_size, target_size = None, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         if target_size is None:\n",
    "#             target_size=(299, 299)\n",
    "#         self.target_size = target_size\n",
    "#         self.crop_size = crop_size\n",
    "\n",
    "#     def img_random_crop(self, img):\n",
    "#         h, w = img.shape[:2]\n",
    "#         new_h, new_w = self.crop_size[:2]\n",
    "        \n",
    "#         # Calculate random cropping offsets\n",
    "#         top = np.random.randint(0, h - new_h)\n",
    "#         left = np.random.randint(0, w - new_w)\n",
    "\n",
    "#         # Perform random crop\n",
    "#         img = img[top:top + new_h, left:left + new_w]\n",
    "\n",
    "#         return img\n",
    "    \n",
    "#     def img_resize(self, img):\n",
    "#         img = resize(img, self.target_size, anti_aliasing=True)\n",
    "#         return img\n",
    "    \n",
    "#     def flow_from_dataframe(self, *args, **kwargs):\n",
    "#         for batch_x, batch_y in super().flow_from_dataframe(*args, **kwargs):        \n",
    "#             try:\n",
    "#                 batch_x = np.array([self.img_random_crop(img) for img in batch_x])\n",
    "#                 batch_x = np.array([self.img_resize(img) for img in batch_x])\n",
    "#                 batch_x = keras.applications.xception.preprocess_input(batch_x) #Xception model requires this, normalizing the pixel values\n",
    "#                 yield (batch_x, batch_y)\n",
    "#             except Exception as e:\n",
    "#                 # Print the file paths of the images causing the error\n",
    "#                 print(\"Error processing batch. File paths:\")\n",
    "#                 print(batch_x)\n",
    "                \n",
    "#                 # Optionally, print the specific error message\n",
    "#                 print(\"Error message:\", e)\n",
    "                \n",
    "#                 continue\n",
    "            \n",
    "# print(id(CustomImageDataGenerator))\n",
    "\n",
    "# # Define image data generator with data augmentation and random crop\n",
    "# datagen = CustomImageDataGenerator(\n",
    "#     #horizontal_flip=True,\n",
    "#     #fill_mode='nearest',\n",
    "#     crop_size=(897,897))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "print(bfce_test.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_and_save_images(DF, source_dir, save_dir, target_size=(299, 299), crop_size=897):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for row in tqdm(Train_DF.iterrows()):\n",
    "        # Read image\n",
    "        img_path = os.path.join(source_dir, row['screenshots'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue  # Skip if unable to read image\n",
    "        # # # Random crop\n",
    "        # h, w = img.shape[:2]\n",
    "        # crop_size = min(crop_size, h, w)\n",
    "        # # Calculate random cropping offsets\n",
    "        # top = np.random.randint(0, h - crop_size + 1)\n",
    "        # left = np.random.randint(0, w - crop_size + 1)\n",
    "        # Perform crop\n",
    "        # img = img[top:top + crop_size, left:left + crop_size]\n",
    "\n",
    "        # Resize\n",
    "        img = resize(img, target_size, anti_aliasing=True, preserve_range=True)\n",
    "        \n",
    "\n",
    "        # Save preprocessed image with original filename\n",
    "        filename = os.path.basename(img_path)\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        cv2.imwrite(save_path, img)\n",
    "    \n",
    "\n",
    "source_directory = '/Users/sammcmanagan/AA Assignment 2/images'\n",
    "save_directory = '/Users/sammcmanagan/AA Assignment 2/resized_images'\n",
    "\n",
    "\n",
    "\n",
    "###30,161 images in the train df that aren't 1920x1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CHECKING ISSUES WITH LOADING SOME OF THE IMAGES\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def check_images(directory):\n",
    "    error_count = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            total_images += 1\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Do nothing, just open the image to check for errors\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image {filename}: {e}\")\n",
    "                error_count += 1\n",
    "                \n",
    "    print(f\"Total images checked: {total_images}\")\n",
    "    print(f\"Errors encountered: {error_count}\")\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"/Users/sammcmanagan/AA Assignment 2/Images\"\n",
    "tqdm(check_images(directory_path))\n",
    "\n",
    "##three images won't load in the directory, these will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def none_images():\n",
    "#     Noimg = 0\n",
    "#     imgs = 0\n",
    "#     for _, row in tqdm(Valid_DF.iterrows()):\n",
    "#         img_path = row['screenshots']\n",
    "#         img = cv2.imread(img_path)\n",
    "#         if img is None:  # Skip if unable to read image\n",
    "#             Noimg += 1\n",
    "#             continue\n",
    "#         imgs+=1\n",
    "#     print(Noimg)\n",
    "#     print(imgs)\n",
    "# none_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def get_files_not_in_resized(original_dir, resized_dir):\n",
    "#     original_files = set(os.listdir(original_dir))\n",
    "#     resized_files = set(os.listdir(resized_dir))\n",
    "    \n",
    "#     files_not_in_resized = original_files - resized_files\n",
    "    \n",
    "#     return files_not_in_resized\n",
    "\n",
    "# # Example usage\n",
    "# original_dir = '/Users/sammcmanagan/AA Assignment 2/Images'\n",
    "# resized_dir = '/Users/sammcmanagan/AA Assignment 2/resized_images'\n",
    "\n",
    "# files_not_in_resized = get_files_not_in_resized(original_dir, resized_dir)\n",
    "# print(\"Files not present in resized_images directory:\")\n",
    "# for file_name in files_not_in_resized:\n",
    "#     print(file_name)\n",
    "# print(len(files_not_in_resized))\n",
    "# print(len(Test_DF))\n",
    "\n",
    "# directory='/Users/sammcmanagan/AA Assignment 2/Images'\n",
    "# abs_file_names = []\n",
    "\n",
    "# for file_name in Valid_DF['screenshots']:\n",
    "#     tmp = os.path.abspath(directory+os.sep+file_name)\n",
    "#     abs_file_names.append(tmp)\n",
    "\n",
    "# # update dataframe\n",
    "# Train_DF['screenshots'] = abs_file_names\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# print(Train_DF['screenshots'].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path=Train_DF['screenshots']\n",
    "# for screenshot in tqdm(Train_DF['screenshots']):\n",
    "#     file_path=screenshot\n",
    "#     try:\n",
    "#         image=cv2.imread(file_path)\n",
    "#         shape=image.shape\n",
    "#     except:\n",
    "#         print('Invalid image file')\n",
    "#         print(screenshot)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "221ab5ba4d875600bd6bb0e7eee0cec001efdea31b25afc3ad4fb9d8815d7c77"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
